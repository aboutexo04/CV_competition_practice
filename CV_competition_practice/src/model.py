# src/model.py

"""
ëª¨ë¸ ì •ì˜ ë° ìƒì„± ëª¨ë“ˆ
"""
import torch
import torch.nn as nn
import timm

# ëª¨ë¸ë³„ ì„¤ì •
MODEL_CONFIGS = {
    'efficientnet_b0': {'display_name': 'EfficientNet-B0', 'short_name': 'effnet-b0'},
    'efficientnet_b1': {'display_name': 'EfficientNet-B1', 'short_name': 'effnet-b1'},
    'efficientnet_b2': {'display_name': 'EfficientNet-B2', 'short_name': 'effnet-b2'},
    'efficientnet_b3': {'display_name': 'EfficientNet-B3', 'short_name': 'effnet-b3'},
    'resnet18': {'display_name': 'ResNet-18', 'short_name': 'resnet18'},
    'resnet34': {'display_name': 'ResNet-34', 'short_name': 'resnet34'},
    'resnet50': {'display_name': 'ResNet-50', 'short_name': 'resnet50'},
    'resnet101': {'display_name': 'ResNet-101', 'short_name': 'resnet101'},
    'vit_tiny_patch16_224': {'display_name': 'ViT-Tiny', 'short_name': 'vit-tiny'},
    'vit_small_patch16_224': {'display_name': 'ViT-Small', 'short_name': 'vit-small'},
    'convnext_tiny': {'display_name': 'ConvNeXt-Tiny', 'short_name': 'convnext-tiny'},
    'convnext_small': {'display_name': 'ConvNeXt-Small', 'short_name': 'convnext-small'},
    'mobilenetv3_small_100': {'display_name': 'MobileNetV3-Small', 'short_name': 'mobilenet-small'},
    'mobilenetv3_large_100': {'display_name': 'MobileNetV3-Large', 'short_name': 'mobilenet-large'},
}


def get_model(model_name, num_classes=10, pretrained=True):
    """
    Config ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ ìƒì„±
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: 'efficientnet_b0', 'resnet50')
        num_classes: ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜
        pretrained: ImageNet pretrained weights ì‚¬ìš© ì—¬ë¶€
        
    Returns:
        model: PyTorch ëª¨ë¸
    """
    try:
        model = timm.create_model(
            model_name,
            pretrained=pretrained,
            num_classes=num_classes
        )
        
        # Display name ê°€ì ¸ì˜¤ê¸°
        model_config = MODEL_CONFIGS.get(
            model_name, 
            {'display_name': model_name, 'short_name': model_name}
        )
        display_name = model_config['display_name']
        
        print(f"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ: {display_name} ({model_name})")
        if pretrained:
            print(f"   Pretrained weights ì‚¬ìš©")
        
        return model
    
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {model_name}")
        print(f"   Error: {e}")
        raise


def print_model_list(current_model=None):
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ëª©ë¡ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶œë ¥
    
    Args:
        current_model: í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ì´ë¦„ (ê°•ì¡° í‘œì‹œìš©)
    """
    print("=" * 70)
    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")
    print("=" * 70)

    # ëª¨ë¸ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
    model_groups = {
        'EfficientNet': [k for k in MODEL_CONFIGS.keys() if 'efficientnet' in k],
        'ResNet': [k for k in MODEL_CONFIGS.keys() if 'resnet' in k],
        'ViT (Vision Transformer)': [k for k in MODEL_CONFIGS.keys() if 'vit' in k],
        'ConvNeXt': [k for k in MODEL_CONFIGS.keys() if 'convnext' in k],
        'MobileNet': [k for k in MODEL_CONFIGS.keys() if 'mobilenet' in k],
    }

    idx = 1
    for group_name, models in model_groups.items():
        if models:
            print(f"\nğŸ”¹ {group_name}:")
            for model_name in models:
                config = MODEL_CONFIGS[model_name]
                marker = "ğŸ‘‰ " if model_name == current_model else "   "
                print(f"{marker}{idx:2d}. {config['display_name']:25s} ({model_name})")
                idx += 1

    print("\n" + "=" * 70)
    if current_model:
        model_config = MODEL_CONFIGS.get(
            current_model,
            {'display_name': current_model}
        )
        print(f"âœ… í˜„ì¬ ì„ íƒëœ ëª¨ë¸: {model_config['display_name']} ({current_model})")
    print(f"ğŸ’¡ ëª¨ë¸ ë³€ê²½ ë°©ë²•: config.update(MODEL_NAME='ëª¨ë¸ëª…')")
    print("=" * 70)


def get_model_info(model):
    """
    ëª¨ë¸ ì •ë³´ ë°˜í™˜

    Args:
        model: PyTorch ëª¨ë¸

    Returns:
        dict: ëª¨ë¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    return {
        'total_params': total_params,
        'trainable_params': trainable_params,
        'frozen_params': total_params - trainable_params
    }


def print_model_info(model, device, model_name=None):
    """
    ëª¨ë¸ ì •ë³´ë¥¼ ê¹”ë”í•˜ê²Œ ì¶œë ¥

    Args:
        model: PyTorch ëª¨ë¸
        device: ëª¨ë¸ì´ ìœ„ì¹˜í•œ ë””ë°”ì´ìŠ¤
        model_name: ëª¨ë¸ ì´ë¦„ (ì„ íƒ)
    """
    info = get_model_info(model)
    
    # Display name ê°€ì ¸ì˜¤ê¸°
    if model_name:
        model_config = MODEL_CONFIGS.get(
            model_name,
            {'display_name': model_name}
        )
        display_name = model_config['display_name']
    else:
        display_name = "Unknown"

    print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´")
    print("=" * 70)
    print(f"  ëª¨ë¸ ì´ë¦„:           {display_name}")
    print(f"  ì „ì²´ íŒŒë¼ë¯¸í„°:       {info['total_params']:,}")
    print(f"  í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°:  {info['trainable_params']:,}")
    print(f"  ê³ ì • íŒŒë¼ë¯¸í„°:       {info['frozen_params']:,}")
    print(f"  ë””ë°”ì´ìŠ¤:            {device}")
    print("=" * 70)


def get_optimizer(model, config):
    """
    Config ê¸°ë°˜ìœ¼ë¡œ optimizer ìƒì„±
    
    Args:
        model: PyTorch ëª¨ë¸
        config: Config ê°ì²´
        
    Returns:
        optimizer: PyTorch optimizer
    """
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=config.LR,
        weight_decay=getattr(config, 'WEIGHT_DECAY', 1e-4)
    )
    
    return optimizer


def get_scheduler(optimizer, config):
    """
    Config ê¸°ë°˜ìœ¼ë¡œ learning rate scheduler ìƒì„±
    
    Args:
        optimizer: PyTorch optimizer
        config: Config ê°ì²´
        
    Returns:
        scheduler: PyTorch scheduler
    """
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.EPOCHS,
        eta_min=1e-6
    )
    
    return scheduler


def freeze_layers(model, freeze_ratio=0.5):
    """
    ëª¨ë¸ì˜ ì¼ë¶€ ë ˆì´ì–´ë¥¼ ë™ê²°

    Args:
        model: PyTorch ëª¨ë¸
        freeze_ratio (float): ë™ê²°í•  ë ˆì´ì–´ ë¹„ìœ¨ (0.0 ~ 1.0)

    Returns:
        model: ë ˆì´ì–´ê°€ ë™ê²°ëœ ëª¨ë¸
    """
    params = list(model.parameters())
    freeze_count = int(len(params) * freeze_ratio)

    for i, param in enumerate(params):
        if i < freeze_count:
            param.requires_grad = False

    return model


def unfreeze_all(model):
    """
    ëª¨ë¸ì˜ ëª¨ë“  ë ˆì´ì–´ë¥¼ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •

    Args:
        model: PyTorch ëª¨ë¸

    Returns:
        model: ëª¨ë“  ë ˆì´ì–´ê°€ í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë¸
    """
    for param in model.parameters():
        param.requires_grad = True

    return model


# ============================================
# Backward compatibility
# ============================================

def create_model(model_name, num_classes=10, pretrained=True):
    """ê¸°ì¡´ í•¨ìˆ˜ëª… (backward compatibility)"""
    return get_model(model_name, num_classes, pretrained)